{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0898e7c5",
   "metadata": {},
   "source": [
    "## Q1: Implement the L1 and L2 loss functions Exercise: Implement the numpy vectorized version of the L1 loss. You may find the function abs(x) (absolute value of x) useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8575c3a",
   "metadata": {},
   "source": [
    "#### Import Some Libarares we will need .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17baa25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c61e76",
   "metadata": {},
   "source": [
    "### Start Implemntaion ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71652e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#L1 Function Implementaion\n",
    "def L1(yhat, y):\n",
    "    loss = np.sum(np.abs(yhat - y))\n",
    "    return loss\n",
    "\n",
    "#L2 Function Implementaion\n",
    "def L2(yhat, y):\n",
    "    loss = np.sum(np.square(yhat - y))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6292959a",
   "metadata": {},
   "source": [
    "#### Now We will Test L1 and L2 Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e10430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 = 1.1\n"
     ]
    }
   ],
   "source": [
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y    = np.array([1 ,  0 ,  0 ,  1, 1])\n",
    "\n",
    "l1_loss = L1(yhat,y)\n",
    "\n",
    "print(\"L1 = \" + str(l1_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a31097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 = 0.43\n"
     ]
    }
   ],
   "source": [
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y    = np.array([1 ,  0 ,  0 ,  1, 1])\n",
    "\n",
    "l2_loss = L2(yhat,y)\n",
    "\n",
    "print(\"L2 = \" + str(l2_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e6991d",
   "metadata": {},
   "source": [
    "### Q2: comparing the dot product using parallelism in python vs numpy_dot_product vs using the for_loop and compute the time needed for each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1815e3",
   "metadata": {},
   "source": [
    "#### Firstly Using Parallelism in Python (concurrent.futures) ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c28d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays we will use \n",
    "array_size = 10000\n",
    "array1 = np.random.rand(array_size)\n",
    "array2 = np.random.rand(array_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc4db494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot Product: 2459.500730004382\n",
      "Time taken: 1.046875 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "def dot_product_for_chunk(chunk, arr1, arr2):\n",
    "    return np.dot(arr1[chunk[0]:chunk[1]], arr2[chunk[0]:chunk[1]])\n",
    "\n",
    "def parallel_dot_product(arr1, arr2, num_threads=4):\n",
    "    chunk_size = len(arr1) // num_threads\n",
    "    chunks = [(i * chunk_size, (i + 1) * chunk_size) for i in range(num_threads - 1)]\n",
    "    chunks.append(((num_threads - 1) * chunk_size, len(arr1)))\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        results = executor.map(lambda chunk: dot_product_for_chunk(chunk, arr1, arr2), chunks)\n",
    "\n",
    "    return sum(results)\n",
    "\n",
    "tic = time.process_time()\n",
    "\n",
    "for _ in range(10000):\n",
    "    result_parallel = parallel_dot_product(array1, array2)\n",
    "    \n",
    "toc = time.process_time()\n",
    "\n",
    "print(\"Dot Product:\", result_parallel)\n",
    "print(f\"Time taken: {toc - tic} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ea3772",
   "metadata": {},
   "source": [
    "#### I think this is the second way we can do ZIP maybe parrallel ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cd3e11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot Product: 2459.5007300043812\n",
      "Time in sec: 22.734375\n"
     ]
    }
   ],
   "source": [
    "#the dot product using parallelism\n",
    "tic = time.process_time()\n",
    "for _ in range(10000):\n",
    "    dot_product = sum(array1 * array2 for array1, array2 in zip(array1, array2))\n",
    "\n",
    "toc = time.process_time()\n",
    "\n",
    "print(\"Dot Product:\", dot_product)\n",
    "dt1 = toc - tic\n",
    "print(\"Time in sec:\", dt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c3627c",
   "metadata": {},
   "source": [
    "#### Using NumPy's dot Function ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b423416c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot Product: 2459.500730004382\n",
      "Time taken: 0.140625seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.process_time()\n",
    "\n",
    "for _ in range(10000):\n",
    "    res=array1 @ array2 #or .dot\n",
    "\n",
    "toc = time.process_time()\n",
    "\n",
    "\n",
    "dt1 = toc - tic\n",
    "\n",
    "print(\"Dot Product:\", res)\n",
    "print(f\"Time taken: {dt1}seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d2c4f1",
   "metadata": {},
   "source": [
    "#### using the for_loop ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f73e6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_dot_product(a, b):\n",
    "    result = 0\n",
    "    for i in range(len(a)):\n",
    "        result += a[i] * b[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4051db13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot Product: 2459.5007300043812\n",
      "Time in sec: 29.0\n"
     ]
    }
   ],
   "source": [
    "tic = time.process_time()\n",
    "\n",
    "for _ in range(10000):\n",
    "    slow=slow_dot_product(array1, array2)\n",
    "\n",
    "toc = time.process_time()\n",
    "\n",
    "\n",
    "dt1 = toc - tic\n",
    "\n",
    "print(\"Dot Product:\", slow)\n",
    "print(\"Time in sec:\", dt1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bef998",
   "metadata": {},
   "source": [
    "# Dot Product Calculation Methods Comparison\n",
    "\n",
    "## NumPy's `dot` Function:\n",
    "\n",
    "### 1. Efficiency:\n",
    "- NumPy's `dot` function is highly optimized and implemented in low-level languages like C or Fortran.\n",
    "- Utilizes optimized algorithms and memory management, rendering it highly efficient for array computations.\n",
    "\n",
    "### 2. Fast Execution:\n",
    "- Executes the dot product operation significantly faster compared to a `for` loop.\n",
    "- Leverages vectorized operations and optimized implementation for swift computation.\n",
    "\n",
    "## Parallelism in Python:\n",
    "\n",
    "### 1. Scalability:\n",
    "- Offers performance improvements, especially for larger arrays, by distributing computations across multiple processes or threads.\n",
    "- Enhances performance by leveraging the parallel processing capabilities of the system.\n",
    "\n",
    "### 2. Overheads:\n",
    "- Setting up parallel processes or threads incurs overheads like data splitting, result aggregation, and inter-process communication.\n",
    "- For smaller computations, these overheads might overshadow the performance gains achieved through parallelism.\n",
    "\n",
    "## For Loop:\n",
    "\n",
    "### 1. Least Efficient:\n",
    "- Utilizing a `for` loop for dot product calculation is the least efficient method.\n",
    "- Involves sequential iteration through array elements, resulting in slower execution times.\n",
    "\n",
    "### 2. No Vectorization:\n",
    "- Lack of vectorization in a `for` loop makes it slower compared to optimized functions like NumPy's `dot`, which leverage vectorized operations.\n",
    "\n",
    "---\n",
    "\n",
    "**Conclusion**:\n",
    "- NumPy's `dot` function stands out as highly efficient and optimized for array operations, making it the preferred choice for dot product calculations.\n",
    "- While parallelism can offer significant performance gains, especially for larger arrays, the associated overheads might overshadow the benefits for smaller computations.\n",
    "- Utilizing a `for` loop, being the least efficient method, is generally discouraged for array computations when more optimized libraries like NumPy are available.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
